{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name : Podutur Lahari - DE126\n",
        "\n",
        "Date : 21-11-2024"
      ],
      "metadata": {
        "id": "Dp-cxNcj2BBZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "585a855c-4bb9-4ba4-9452-6381a437f2e8",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "AwxUFxye18nl",
        "outputId": "58e1530a-2a8a-4282-ede8-c4cf7e0b0d0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-------------+------+------+\n|  Name|date of birth|Gender|salary|\n+------+-------------+------+------+\n|   Ram|   1991-04-01|     M|  3000|\n|  Mike|   2000-05-19|     M|  4000|\n|Rohini|   1978-09-05|     M|  4000|\n| Maria|   1967-12-01|     F|  4000|\n| Jenis|   1980-02-17|     F|  1200|\n+------+-------------+------+------+\n\n+----------+-------------+------+------+\n|personname|date of birth|Gender|salary|\n+----------+-------------+------+------+\n|       Ram|   1991-04-01|     M|  3000|\n|      Mike|   2000-05-19|     M|  4000|\n|    Rohini|   1978-09-05|     M|  4000|\n|     Maria|   1967-12-01|     F|  4000|\n|     Jenis|   1980-02-17|     F|  1200|\n+----------+-------------+------+------+\n\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Importing necessary libraries\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create a spark session\n",
        "spark = SparkSession.builder.appName('pyspark - example join').getOrCreate()\n",
        "\n",
        "# Create data in dataframe\n",
        "data = [(('Ram'), '1991-04-01', 'M', 3000),\n",
        "        (('Mike'), '2000-05-19', 'M', 4000),\n",
        "        (('Rohini'), '1978-09-05', 'M', 4000),\n",
        "        (('Maria'), '1967-12-01', 'F', 4000),\n",
        "        (('Jenis'), '1980-02-17', 'F', 1200)]\n",
        "\n",
        "# Column names in dataframe\n",
        "columns = [\"Name\", \"DOB\", \"Gender\", \"salary\"]\n",
        "\n",
        "# Create the spark dataframe\n",
        "df = spark.createDataFrame(data=data,\n",
        "                           schema=columns)\n",
        "df.withColumnRenamed(\"DOB\",\"date of birth\").show()\n",
        "df.withColumnRenamed(\"DOB\",\"date of birth\").withColumnRenamed(\"Name\",\"personname\").show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "59994b95-bc09-4eb0-a460-ec776aed0c29",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "4s7P2ROq18nt",
        "outputId": "086a8f9f-68e8-4a27-eb36-2f6f0cf00baa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+----------+------+------+\n|category|       DOB|  name|salary|\n+--------+----------+------+------+\n|       M|1991-04-01|   Ram|  3000|\n|       M|2000-05-19|  Mike|  4000|\n|       M|1978-09-05|Rohini|  4000|\n|       F|1967-12-01| Maria|  4000|\n|       F|1980-02-17| Jenis|  1200|\n+--------+----------+------+------+\n\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Importing necessary libraries using select exp\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create a spark session\n",
        "spark = SparkSession.builder.appName('pyspark - example join').getOrCreate()\n",
        "\n",
        "# Create data in dataframe\n",
        "data = [(('Ram'), '1991-04-01', 'M', 3000),\n",
        "        (('Mike'), '2000-05-19', 'M', 4000),\n",
        "        (('Rohini'), '1978-09-05', 'M', 4000),\n",
        "        (('Maria'), '1967-12-01', 'F', 4000),\n",
        "        (('Jenis'), '1980-02-17', 'F', 1200)]\n",
        "\n",
        "# Column names in dataframe\n",
        "columns = [\"Name\", \"DOB\", \"Gender\", \"salary\"]\n",
        "\n",
        "# Create the spark dataframe\n",
        "df = spark.createDataFrame(data=data,\n",
        "                           schema=columns)\n",
        "\n",
        "\n",
        "data = df.selectExpr(\"Gender as category\",\"DOB\",\"Name as name\",\"salary\")\n",
        "\n",
        "data.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {
            "byteLimit": 2048000,
            "implicitDf": true,
            "rowLimit": 10000
          },
          "inputWidgets": {},
          "nuid": "4ee0f820-23a3-470f-94f0-6727859ed055",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        },
        "id": "IEpdkgS_18nu",
        "outputId": "edeaa185-0099-4ba9-9da1-ef81697a6993"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----------+------+------+\n|  Name|       DOB|Gender|Amount|\n+------+----------+------+------+\n|   Ram|1991-04-01|     M|  3000|\n|  Mike|2000-05-19|     M|  4000|\n|Rohini|1978-09-05|     M|  4000|\n| Maria|1967-12-01|     F|  4000|\n| Jenis|1980-02-17|     F|  1200|\n+------+----------+------+------+\n\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Select the 'salary' as 'Amount' using aliasing\n",
        "# Select remaining with their original name\n",
        "data = df.select(col(\"Name\"),col(\"DOB\"),\n",
        "                 col(\"Gender\"),\n",
        "                 col(\"salary\").alias('Amount'))\n",
        "data.show()\n"
      ]
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "dashboards": [],
      "environmentMetadata": null,
      "language": "python",
      "notebookMetadata": {
        "mostRecentlyExecutedCommandWithImplicitDF": {
          "commandId": -1,
          "dataframes": [
            "_sqldf"
          ]
        },
        "pythonIndentUnit": 2
      },
      "notebookName": "Selecting, Renaming, Filtering Data in a Pandas DataFrame",
      "widgets": {}
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}